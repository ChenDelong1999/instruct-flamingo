{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219685\n"
     ]
    }
   ],
   "source": [
    "import json, os, cv2, random, tqdm\n",
    "\n",
    "dataset_path = '/cpfs/shared/research-llm/instruc_data_en/multimodal_instruct_tuning/funqa/raw/'\n",
    "frame_dir = '/cpfs/shared/research-llm/instruc_data_en/multimodal_instruct_tuning/funqa/frames/'\n",
    "\n",
    "split = 'train'\n",
    "video_dir = os.path.join(dataset_path, split)\n",
    "frame_dir = os.path.join(frame_dir, split)\n",
    "os.makedirs(frame_dir, exist_ok=True)\n",
    "\n",
    "samples = json.load(open(os.path.join(dataset_path, f'annotation_with_ID/funqa_{split}.json')))\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def extract_frames(video_path, frame_dir):\n",
    "    # 创建以视频路径basename为名称的文件夹\n",
    "    video_name = os.path.basename(video_path)\n",
    "    output_folder = os.path.join(frame_dir, os.path.splitext(video_name)[0])\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # 打开视频文件\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # 确认视频文件是否打开成功\n",
    "    if not cap.isOpened():\n",
    "        print(\"无法打开视频文件。\")\n",
    "        return [], []\n",
    "\n",
    "    # 获取视频的帧率和总帧数\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # 总时长\n",
    "    total_seconds = total_frames / fps\n",
    "    num_frames = 8 if total_seconds < 16 else 16\n",
    "\n",
    "    # 计算均匀抽帧的间隔\n",
    "    interval = total_frames // num_frames\n",
    "\n",
    "    # 保存帧图像路径和每个图像对应的秒数\n",
    "    frame_paths = []\n",
    "    frame_seconds = []\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        # 计算抽取帧的位置\n",
    "        frame_idx = i * interval\n",
    "\n",
    "        # 设置视频的当前帧位置\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "\n",
    "        # 读取当前帧\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # 保存帧图像\n",
    "        frame_filename = os.path.join(output_folder, f\"frame_{i:04d}.jpg\")\n",
    "        cv2.imwrite(frame_filename, cv2.resize(frame, (336,336)))\n",
    "        \n",
    "        # 计算当前帧对应的秒数\n",
    "        seconds = i * interval / fps\n",
    "\n",
    "        # 保留两位小数\n",
    "        seconds = round(seconds, 2)\n",
    "\n",
    "        frame_paths.append(frame_filename)\n",
    "        frame_seconds.append(seconds)\n",
    "\n",
    "    # 释放视频文件和资源\n",
    "    cap.release()\n",
    "\n",
    "    return frame_paths, frame_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/219685 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219685/219685 [00:01<00:00, 110507.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204325\n"
     ]
    }
   ],
   "source": [
    "subdir_mapping = {\n",
    "    'H': 'humor',\n",
    "    'C': 'creative',\n",
    "    'M': 'magic'\n",
    "}\n",
    "\n",
    "extracted_videos = {}\n",
    "all_samples = []\n",
    "for sample in tqdm.tqdm(samples):\n",
    "    # print(sample)\n",
    "    sub_dir = subdir_mapping[sample['visual_input'][0]]\n",
    "    video_path = os.path.join(video_dir, f'{split}_{sub_dir}', sample['visual_input'])\n",
    "\n",
    "    if sample['visual_input'] not in extracted_videos:\n",
    "        frame_paths, timestamps = extract_frames(video_path, frame_dir)\n",
    "        extracted_videos[sample['visual_input']] = (frame_paths, timestamps)\n",
    "    else:\n",
    "        frame_paths, timestamps = extracted_videos[sample['visual_input']]\n",
    "\n",
    "    video_frames_str = ''\n",
    "    for i in range(len(frame_paths)):\n",
    "        video_frames_str += f'{timestamps[i]}s: <img_path>{frame_paths[i]}<img_path>\\n'\n",
    "    \n",
    "    if random.random() < 0.5:\n",
    "        input_str = sample['instruction'] + '\\n' + video_frames_str\n",
    "    else:\n",
    "        input_str = video_frames_str + sample['instruction']\n",
    "\n",
    "    if sample['output'].startswith(' '):\n",
    "        sample['output'] = sample['output'][1:]\n",
    "\n",
    "    if sample['task'][1] != '1':\n",
    "        all_samples.append({\n",
    "            'input': input_str,\n",
    "            'output': sample['output']\n",
    "        })\n",
    "\n",
    "print(len(all_samples))\n",
    "os.makedirs('converted_datasets/funqa', exist_ok=True)\n",
    "json.dump(all_samples, open(f'converted_datasets/funqa/funqa-{split}.json', 'w'), indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
