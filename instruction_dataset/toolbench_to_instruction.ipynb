{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26999\n"
     ]
    }
   ],
   "source": [
    "import json, os, random\n",
    "\n",
    "toolbench_data_path = '/cpfs/shared/research-llm/instruc_data_en/language_only_instruct_tuning/toolbench/data'\n",
    "\n",
    "# samples = json.load(open(os.path.join(toolbench_data_path,'toolllama_G123_dfs_train.json')))\n",
    "samples = json.load(open(os.path.join(toolbench_data_path,'toolllama_G123_dfs_train.json')))\n",
    "\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample(sample):\n",
    "    # print(sample['id'])\n",
    "    for content in sample['conversations']:\n",
    "        system_message = \"You are AutoGPT, you can use many tools(functions) to do the following task.\\nFirst I will give you the task description, and your task start.\\nAt each step, you need to give your thought to analyze the status now and what to do next, with a function call to actually excute your step. Your output should follow this format:\\nThought:\\nAction\\nAction Input:\\n\\nAfter the call, you will get the call result, and you are now in a new state.\\nThen you will analyze your status now, then decide what to do next...\\nAfter many (Thought-call) pairs, you finally perform the task, then you can give your finial answer.\\nRemember: \\n1.the state change is irreversible, you can't go back to one of the former state, if you want to restart the task, say \\\"I give up and restart\\\".\\n2.All the thought is short, at most in 5 sentence.\\n3.You can do more then one trys, so if your plan is to continusly try some conditions, you can do one of the conditions per try.\\nLet's Begin!\\nTask description: You should use functions to help handle the real time user querys. Remember:\\n1.ALWAYS call \\\"Finish\\\" function at the end of the task. And the final answer should contain enough information to show to the user,If you can't handle the task, or you find that function calls always fail(the function is not valid now), use function Finish->give_up_and_restart.\\n2.Do not use origin tool names, use only subfunctions' names.\\n\"\n",
    "        print(f\"ðŸ”¥{content['from']}\")\n",
    "        print(content['value'].replace(system_message, ''))\n",
    "        print('-'*64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26999\n",
      "Writing to converted_datasets/toolbench/toolbench.json, total 80210 items\n"
     ]
    }
   ],
   "source": [
    "system_message = \"You are AutoGPT, you can use many tools(functions) to do the following task.\\nFirst I will give you the task description, and your task start.\\nAt each step, you need to give your thought to analyze the status now and what to do next, with a function call to actually excute your step. Your output should follow this format:\\nThought:\\nAction\\nAction Input:\\n\\nAfter the call, you will get the call result, and you are now in a new state.\\nThen you will analyze your status now, then decide what to do next...\\nAfter many (Thought-call) pairs, you finally perform the task, then you can give your finial answer.\\nRemember: \\n1.the state change is irreversible, you can't go back to one of the former state, if you want to restart the task, say \\\"I give up and restart\\\".\\n2.All the thought is short, at most in 5 sentence.\\n3.You can do more then one trys, so if your plan is to continusly try some conditions, you can do one of the conditions per try.\\nLet's Begin!\\nTask description: You should use functions to help handle the real time user querys. Remember:\\n1.ALWAYS call \\\"Finish\\\" function at the end of the task. And the final answer should contain enough information to show to the user,If you can't handle the task, or you find that function calls always fail(the function is not valid now), use function Finish->give_up_and_restart.\\n2.Do not use origin tool names, use only subfunctions' names.\\n\"\n",
    "\n",
    "\n",
    "\n",
    "def split_one_sample(sample):\n",
    "    output_data = []\n",
    "    user_tag = '### Human: '\n",
    "    assistant_tag = '### Assistant: '\n",
    "\n",
    "    conversation_history = \"\"\n",
    "    for i, conversation in enumerate(sample['conversations']):\n",
    "        if conversation['from'] in ['user', 'function', 'system']:\n",
    "            if i==0:\n",
    "                conversation_history = 'Toolbench System Message -- ' + conversation['value'].replace(system_message, '')\n",
    "            else:\n",
    "                conversation_history += f\"\\n{user_tag}{conversation['value']}\"\n",
    "            \n",
    "        elif conversation['from'] == 'assistant':\n",
    "            output = conversation['value']\n",
    "            if output.startswith('\\n'):\n",
    "                output = output[1:]\n",
    "            output_item = {\n",
    "                'input': conversation_history.strip(),\n",
    "                'output': output\n",
    "            }\n",
    "            output_data.append(output_item)\n",
    "            conversation_history += f\"\\n{assistant_tag}{output}\"\n",
    "        \n",
    "    return output_data\n",
    "\n",
    "all_samples = []\n",
    "os.makedirs('converted_datasets/toolbench', exist_ok=True)\n",
    "print(len(samples))\n",
    "for sample in samples:\n",
    "    all_samples += split_one_sample(sample)\n",
    "    \n",
    "print(f'Writing to converted_datasets/toolbench/toolbench.json, total {len(all_samples)} items')\n",
    "json.dump(all_samples, open('converted_datasets/toolbench/toolbench-train.json', 'w'), indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
